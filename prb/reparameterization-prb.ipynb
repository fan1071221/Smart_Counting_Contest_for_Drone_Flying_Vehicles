{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7cbe5ee",
   "metadata": {},
   "source": [
    "# Reparameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330a635",
   "metadata": {},
   "source": [
    "## Yolov7-PRB reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72366828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from copy import deepcopy\n",
    "from models.yolo import Model\n",
    "import torch\n",
    "from utils.torch_utils import select_device, is_parallel\n",
    "import yaml\n",
    "\n",
    "cfg_path = r\"cfg/deploy/yolov7-PRB.yaml\"\n",
    "ckpt_path = r\"yolov7-prb_training.pt\"  # checkpoints of yolov7-prb with IDetect layer\n",
    "save_path = r\"yolov7-prb.pt\"  # output file path\n",
    "\n",
    "device = select_device('0', batch_size=1)\n",
    "# model trained by cfg/training/*.yaml\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "# reparameterized model in cfg/deploy/*.yaml\n",
    "model = Model(cfg_path, ch=3, nc=80).to(device)\n",
    "\n",
    "with open(cfg_path) as f:\n",
    "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "anchors = len(yml['anchors'])\n",
    "\n",
    "# copy intersect weights\n",
    "state_dict = ckpt['model'].float().state_dict()\n",
    "exclude = []\n",
    "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
    "model.load_state_dict(intersect_state_dict, strict=False)\n",
    "model.names = ckpt['model'].names\n",
    "model.nc = ckpt['model'].nc\n",
    "\n",
    "# reparametrized YOLOR\n",
    "for i in range((model.nc+5)*anchors):  \n",
    "    model.state_dict()['model.108.m.0.weight'].data[i, :, :, :] *= state_dict['model.108.im.0.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.108.m.1.weight'].data[i, :, :, :] *= state_dict['model.108.im.1.implicit'].data[:, i, : :].squeeze()\n",
    "    model.state_dict()['model.108.m.2.weight'].data[i, :, :, :] *= state_dict['model.108.im.2.implicit'].data[:, i, : :].squeeze()\n",
    "model.state_dict()['model.108.m.0.bias'].data += state_dict['model.108.m.0.weight'].mul(state_dict['model.108.ia.0.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.108.m.1.bias'].data += state_dict['model.108.m.1.weight'].mul(state_dict['model.108.ia.1.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.108.m.2.bias'].data += state_dict['model.108.m.2.weight'].mul(state_dict['model.108.ia.2.implicit']).sum(1).squeeze()\n",
    "model.state_dict()['model.108.m.0.bias'].data *= state_dict['model.108.im.0.implicit'].data.squeeze()\n",
    "model.state_dict()['model.108.m.1.bias'].data *= state_dict['model.108.im.1.implicit'].data.squeeze()\n",
    "model.state_dict()['model.108.m.2.bias'].data *= state_dict['model.108.im.2.implicit'].data.squeeze()\n",
    "\n",
    "# model to be saved\n",
    "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
    "        'optimizer': None,\n",
    "        'training_results': None,\n",
    "        'epoch': -1}\n",
    "\n",
    "# save reparameterized model\n",
    "torch.save(ckpt, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
